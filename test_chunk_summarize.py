import logging
import os
import time

from llm_utils import LLMClient
from ui.workers.llm_summary_thread import chunk_document_with_overlap

# Setup logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Create test directory
test_dir = os.path.join(os.getcwd(), "test_output")
if not os.path.exists(test_dir):
    os.makedirs(test_dir)

# Initialize client
client = LLMClient()
logger.info("LLMClient initialized")

# Create a test document
test_file = os.path.join(test_dir, "large_test.md")
with open(test_file, "w") as f:
    f.write("# Large Test Document\n\n")
    for i in range(1, 1000):
        f.write(
            f"## Section {i}\n\nThis is test section {i}. It contains sample content for testing chunking and summarization.\n\n"
        )

logger.info(f"Created test file: {test_file}")

# Read the test document
with open(test_file, "r") as f:
    content = f.read()

# Create chunks
logger.info("Testing chunking functionality...")
chunks = chunk_document_with_overlap(content, client, 60000, 1000)
logger.info(f"Document split into {len(chunks)} chunks")

# Summarize each chunk
summaries = []
for i, chunk in enumerate(chunks):
    logger.info(f"Summarizing chunk {i+1}/{len(chunks)}...")

    # Summarize with Anthropic Claude
    claude_response = client.generate_response(
        prompt_text=f"Summarize the following text in a paragraph:\n\n{chunk}",
        system_prompt="You are a helpful assistant that summarizes documents.",
        temperature=0.1,
    )

    if claude_response["success"]:
        summaries.append(claude_response["content"])
        logger.info(f"Claude summarization successful for chunk {i+1}")
    else:
        logger.error(
            f"Claude summarization failed: {claude_response.get('error', 'Unknown error')}"
        )

# Combine summaries
combined_summaries = "\n\n".join(
    [
        f"## Chunk {i+1}/{len(chunks)} Summary\n{summary}"
        for i, summary in enumerate(summaries)
    ]
)

# Save combined summaries
combined_file = os.path.join(test_dir, "combined_summaries.md")
with open(combined_file, "w") as f:
    f.write(f"# Combined Chunk Summaries\n\n")
    f.write(combined_summaries)

logger.info(f"Saved combined summaries to: {combined_file}")

# Meta-summarize with Gemini
logger.info("Creating meta-summary with Gemini...")

# Check if Gemini is initialized
if not client.gemini_initialized:
    logger.warning("Gemini not initialized. Attempting to initialize...")
    if not client._init_gemini_client():
        logger.error("Failed to initialize Gemini client. Cannot create meta-summary.")
        exit(1)

meta_prompt = f"""
I've analyzed a document in {len(chunks)} chunks. Below are the summaries for each chunk.
Please create a unified, coherent summary that integrates all information without redundancy.

{combined_summaries}
"""

gemini_response = client.generate_response_with_gemini(
    prompt_text=meta_prompt,
    system_prompt="You are creating a unified summary of a document.",
    temperature=0.1,
)

logger.info(f"Gemini response: {gemini_response}")

if gemini_response["success"]:
    # Save meta-summary
    meta_file = os.path.join(test_dir, "meta_summary.md")
    with open(meta_file, "w") as f:
        f.write("# Meta-Summary (Generated by Gemini)\n\n")
        f.write(gemini_response["content"])

    logger.info(f"Meta-summary saved to: {meta_file}")
else:
    logger.error(
        f"Meta-summary generation failed: {gemini_response.get('error', 'Unknown error')}"
    )
